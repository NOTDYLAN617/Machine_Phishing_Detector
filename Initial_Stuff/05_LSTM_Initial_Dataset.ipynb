{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e643ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341fc17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4024, Val size: 575, Test size: 1150\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"03_Cleaned_Initial_Dataset.csv\")\n",
    "\n",
    "# Assign the text and label columns\n",
    "text_col = \"cleaned_text\"  \n",
    "label_col = \"label_encoded\" \n",
    "\n",
    "# Ensure text is string type and handle missing values\n",
    "df[text_col] = df[text_col].astype(str).fillna(\"\")\n",
    "\n",
    "y = df[label_col]\n",
    "X = df[text_col]\n",
    "\n",
    "# Split Dataset into 80% Training and 20% Testing Sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Further Split 10% Validation from Training Set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.125, random_state=42, stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# Tokenize and Pad Sequences\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "custom_filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n' #exlcude <>\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=max_words, \n",
    "    oov_token=\"<OOV>\",\n",
    "    filters=custom_filters # to ensure <phone> <email> <url> are not filtered out\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq   = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq  = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='pre', truncating='post')\n",
    "X_val_pad   = pad_sequences(X_val_seq, maxlen=max_len, padding='pre', truncating='post')\n",
    "X_test_pad  = pad_sequences(X_test_seq, maxlen=max_len, padding='pre', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65f7d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: np.float64(0.5954424385912992), 1: np.float64(3.1193798449612404)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "weights_dict = dict(enumerate(weights))\n",
    "print(f\"Class Weights: {weights_dict}\")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Build Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848956c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.8789 - loss: 0.4237 - val_accuracy: 0.9826 - val_loss: 0.0642\n",
      "Epoch 2/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.9867 - loss: 0.0616 - val_accuracy: 0.9930 - val_loss: 0.0342\n",
      "Epoch 3/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9979 - loss: 0.0158 - val_accuracy: 0.9826 - val_loss: 0.0527\n",
      "Epoch 4/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.9986 - loss: 0.0096 - val_accuracy: 0.9930 - val_loss: 0.0414\n",
      "\n",
      "Training Complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Training...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=10,              \n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_pad, y_val), # Validation on separate validation set\n",
    "    class_weight=weights_dict, # Applies class weights to handle imbalance\n",
    "    callbacks=[early_stop]     # Early stopping to prevent overfitting\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd31f764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Loss: 0.0342 | Accuracy: 0.9930\n",
      "Test Set Loss: 0.0504 | Accuracy: 0.9852\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[965   1]\n",
      " [ 16 168]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.98      1.00      0.99       966\n",
      "        Spam       0.99      0.91      0.95       184\n",
      "\n",
      "    accuracy                           0.99      1150\n",
      "   macro avg       0.99      0.96      0.97      1150\n",
      "weighted avg       0.99      0.99      0.98      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Validation Set\n",
    "val_loss, val_accuracy = model.evaluate(X_val_pad, y_val, verbose=0)\n",
    "print(f\"Validation Set Loss: {val_loss:.4f} | Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate on Test Set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(f\"Test Set Loss: {test_loss:.4f} | Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "\n",
    "# Convert probabilities to binary labels (0 or 1)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report (precision, recall, f1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Ham\", \"Spam\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
